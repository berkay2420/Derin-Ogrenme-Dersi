{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lpxKlZtTQccC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"mushrooms.csv\")\n"
      ],
      "metadata": {
        "id": "4fF_q5o6Qubb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Soru1,Soru2,Soru3 ve Soru4'ün Random Forest kullanılarak Çözümleri ####\n",
        "#Random Forest kullaranak sınıflandırma işlemi ve sonuç değerlerinin hesaplanması ve ardından Random Search ile hiperparametre optimizasyonu\n",
        "\n",
        "### Random Forest kulanabilmek için tüm değerlerin sayısal olması gerekiyor bu nedenle encoding yapmalıyız\n",
        "dff = df.copy() #daha rahat işlem yapabilmek için ana veri setini kopyaladık\n",
        "\n",
        "categorical_columns = [col for col in dff.columns if dff[col].dtypes == \"O\"] #list comprehension kullanarak kategorik sütünları belirledik\n",
        "categorical_columns = [col for col in dff.columns if col not in ['class']] #hedef değişken olduğu için class sınıfını çıkarıyoruz\n",
        "\n",
        "def one_hot_encoder(dataframe, categorical_cols): #Encoding yapmak için \"One Hot Encoding\" yöntemini tercih ettim ve işlemi fonksiyon haline getirdim\n",
        "  dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=True)\n",
        "  return dataframe\n",
        "\n",
        "dff = one_hot_encoder(dff,categorical_columns ) # Hedef değişken hariç tüm değişkenlere one hot encoding uyguladım\n",
        "\n",
        "y = dff['class'] # hedef değişken\n",
        "X = dff.drop('class', axis=1)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=20)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=46).fit(X_train, y_train)\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "print(\"######################### Hiperparamatre Optimizasyonu Öncesi ##########################\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_pred, y_test):.2f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro'):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro'):.2f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='micro'):.2f}\")\n",
        "print(f\"Karışıklık Matrisi:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"######################### Hiperparamatre Optimizasyonu Sonrası ##########################\")\n",
        "\n",
        "# Random Forest'a olacak toplam ağaçları belirleme işlemi.\n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 80, num = 10)] # List comprehension ile 10 ile 80 arasında eşit aralıklarda 10 sayı ürettik\n",
        "# Ağaçtaki her düğümde (node) özellik sayısının karekökü kadar değer seçilecek\n",
        "max_features = ['sqrt']\n",
        "# Ağaçtaki derinlik\n",
        "max_depth = [2,4]\n",
        "# Ağaçtaki bir düğümü (node) bölmek için gereken minimum örnek sayısı\n",
        "min_samples_split = [2, 5]\n",
        "# Her yaprak düğümde (leaf node) bulunması gereken minimum örnek sayısı\n",
        "min_samples_leaf = [1, 2]\n",
        "# Her ağaç için eğitimin nasıl olacağını belirleme. True ise ağaç verilerden rastgele örnekler alaca\n",
        "# False ise ağaç tüm veri setiyle eğitilecek\n",
        "bootstrap = [True, False]\n",
        "\n",
        "\n",
        "param_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Randomized Search ile hiperparametre optimizasyonu yapacağız. Optimazyomu yapılacak model önceden tanımladığımız \"rf_model\"\n",
        "# param_distributions ise önceden belirledeğimiz parametreler. Model bu parametreler üzerinde deneme yapacak\n",
        "rf_RandomGrid = RandomizedSearchCV(estimator = rf_model, param_distributions = param_grid, cv = 10, verbose=2, n_jobs = 4)\n",
        "\n",
        "rf_RandomGrid.fit(X_train, y_train)\n",
        "\n",
        "best_parameters = rf_RandomGrid.best_params_\n",
        "print(\"Bulunan En İyi Parametler\", best_parameters)\n",
        "\n",
        "# Optimal parametreleri kullanarak yeniden modeli eğitiyoruz\n",
        "rf_model = RandomForestClassifier(n_estimators=72,min_samples_split=2, min_samples_leaf=1, max_features='sqrt', max_depth=4, bootstrap=False).fit(X_train, y_train)\n",
        "y_pred = rf_model.predict(X_test)\n",
        "print(f\"Optimizasyon Sonrası Accuracy:  {accuracy_score(y_pred, y_test):.2f}\")\n",
        "print(f\"Optimizasyon Sonrası Precision: {precision_score(y_test, y_pred, average='macro'):.2f}\")\n",
        "print(f\"Optimizasyon Sonrası Recall: {recall_score(y_test, y_pred, average='macro'):.2f}\")\n",
        "print(f\"Optimizasyon Sonrası F1 Score: {f1_score(y_test, y_pred, average='micro'):.2f}\")\n",
        "print(f\"Optimizasyon Sonrası Karışıklık Matrisi:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evim1qzcRCHx",
        "outputId": "7d708b7f-75c8-40e3-ebea-1cb590f3955b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################### Hiperparamatre Optimizasyonu Öncesi ##########################\n",
            "Accuracy:  0.93\n",
            "Precision: 0.94\n",
            "Recall: 0.93\n",
            "F1 Score: 0.93\n",
            "Karışıklık Matrisi:\n",
            " [[1266    0]\n",
            " [ 167 1005]]\n",
            "######################### Hiperparamatre Optimizasyonu Sonrası ##########################\n",
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
            "Bulunan En İyi Parametler {'n_estimators': 80, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 4, 'bootstrap': False}\n",
            "Optimizasyon Sonrası Accuracy:  0.99\n",
            "Optimizasyon Sonrası Precision: 0.99\n",
            "Optimizasyon Sonrası Recall: 0.99\n",
            "Optimizasyon Sonrası F1 Score: 0.99\n",
            "Optimizasyon Sonrası Karışıklık Matrisi:\n",
            " [[1266    0]\n",
            " [  28 1144]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Support Vector Machine \"Linear Kernel\" kullaranak sınıflandırma işlemi ve sonuç değerlerinin hesaplanması ardından Random Search ile hiperparamatre optimizasyonu yapılması\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"mushrooms.csv\")\n",
        "\n",
        "df[\"class\"].value_counts() # class yani hedef değişkenimizde 2 sınıf var e ve p\n",
        "\n",
        "y = dff['class']\n",
        "X = dff.drop('class', axis=1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=109)\n",
        "\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "\n",
        "clf = svm.SVC(kernel='linear', random_state=47, gamma='scale', C=0.1) # Support Vector Machine Linear Kernel Kullanımı\n",
        "\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"######################### Hiperparamatre Optimizasyonu Öncesi ##########################\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_pred, y_test):.2f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro'):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro'):.2f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='micro'):.2f}\")\n",
        "print(f\"Karışıklık Matrisi:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"######################### Hiperparamatre Optimizasyonu Sonrası ##########################\")\n",
        "\n",
        "parameter_grid = {\n",
        "    \"C\" :  np.logspace(-10, 10, 20), #regülayonu ayarlamak için 10 üzeri -10 ile 10 üzeri 10 arasında 20 yane sayı ürettik\n",
        "    \"kernel\" : ['linear', 'rbf'], #kullanılıcak çekirdek (kernel) belirlemek için.\n",
        "    #linear verileri doğrusal bir şekilde ayırır, rbf (Radial Basis Function ) daha karmaşık veriler için\n",
        "    \"gamma\" : np.logspace(-10, 10, 20) # gamma kernel fonksiyonların etkisini kontrol etmek için kullanılır.\n",
        "    # daha yüksek gamma değeri modelin veriye daha fazla odaklanmasını sağlar\n",
        "}\n",
        "scoring = ['accuracy'] #modelin performansını ölçecek metrikleri belirleme işlemi\n",
        "\n",
        "#modeli eğitim ve test setlerine ayırmak için cross validation kullandık\n",
        "k_fold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
        "\n",
        "random_search_svm = RandomizedSearchCV(estimator = clf, param_distributions = parameter_grid,scoring=scoring, refit='accuracy', n_jobs=-1, cv = k_fold, verbose=0, n_iter = 100)\n",
        "\n",
        "random_search_svm.fit(X_train, y_train)\n",
        "\n",
        "best_parameters = random_search_svm.best_params_\n",
        "print(\"Bulunan En İyi Parametler\", best_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT5tQwaZfGef",
        "outputId": "d8b3421d-7779-41cf-8471-ac8aac27d459"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################### Hiperparamatre Optimizasyonu Öncesi ##########################\n",
            "Accuracy:  1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1 Score: 1.00\n",
            "Karışıklık Matrisi:\n",
            " [[1247    0]\n",
            " [   2 1189]]\n",
            "######################### Hiperparamatre Optimizasyonu Sonrası ##########################\n",
            "Bulunan En İyi Parametler {'kernel': 'linear', 'gamma': 1.1288378916846883e-09, 'C': 885866790.4100796}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Support Vector Machine için Optimal parametreleri kullanarak yeniden modeli eğitiyoruz\n",
        "\n",
        "clf = svm.SVC(kernel='linear', random_state=47, gamma=1.1288378916846883e-09, C=885866790.4100796)\n",
        "\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"######################### Support Vector Machine Hiperparamatre Optimizasyonu Sonrası ##########################\")\n",
        "print(f\"Optimizasyon Sonrası Accuracy:  {accuracy_score(y_pred, y_test):.2f}\")\n",
        "print(f\"Optimizasyon Sonrası Precision: {precision_score(y_test, y_pred, average='macro'):.2f}\")\n",
        "print(f\"Optimizasyon Sonrası Recall: {recall_score(y_test, y_pred, average='macro'):.2f}\")\n",
        "print(f\"Optimizasyon Sonrası F1 Score: {f1_score(y_test, y_pred, average='micro'):.2f}\")\n",
        "print(f\"Optimizasyon Sonrası Karışıklık Matrisi:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZsljMLRzLCA",
        "outputId": "37a23e14-a262-47e8-850a-05bc73c7c62b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################### Support Vector Machine Hiperparamatre Optimizasyonu Sonrası ##########################\n",
            "Optimizasyon Sonrası Accuracy:  1.00\n",
            "Optimizasyon Sonrası Precision: 1.00\n",
            "Optimizasyon Sonrası Recall: 1.00\n",
            "Optimizasyon Sonrası F1 Score: 1.00\n",
            "Optimizasyon Sonrası Karışıklık Matrisi:\n",
            " [[1247    0]\n",
            " [   0 1191]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gaussian Naive Bayes kullanılarak sınıflandırma işlemi ve sonuç değerlerinin hesaplanması arından Grid Search ile hiperparametre optimizasyonu yapılması\n",
        "\n",
        "df = pd.read_csv(\"mushrooms.csv\")\n",
        "\n",
        "categorical_columns = [col for col in df.columns if df[col].dtypes == \"O\"] #list comprehension kullanarak kategorik sütünları belirledik\n",
        "categorical_columns = [col for col in df.columns if col not in ['class']]\n",
        "\n",
        "df = one_hot_encoder(df,categorical_columns )\n",
        "\n",
        "y = df['class']\n",
        "X = df.drop('class', axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=125)\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "model = GaussianNB()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"######################### Hiperparamatre Optimizasyonu Öncesi ##########################\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_pred, y_test):.2f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='macro'):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='macro'):.2f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='micro'):.2f}\")\n",
        "print(f\"Karışıklık Matrisi:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"######################### Hiperparamatre Optimizasyonu Sonrası ##########################\")\n",
        "\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "cv_method = RepeatedStratifiedKFold(n_splits=5,\n",
        "                                    n_repeats=3,\n",
        "                                    random_state=999)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
        "# Gaussian Naive Bayes sadece tek bir tane argüman alır. \"var_smoothing\" = Hesaplama kararlılığı için varyanslara eklenen tüm özelliklerin en büyük varyansının kısmı.\n",
        "# Yani varyans (farklılık/varience) hesaplamalardan sıfır elde edilmemesi için varyans değerine etklenen küçük bir miktardır\n",
        "# farklılıklar sıfırdan büyük olursa model daha kararlı tahminler yapabilir.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "gs_NB = GridSearchCV(estimator=model,\n",
        "                     param_grid=params_NB,\n",
        "                     cv=cv_method,\n",
        "                     verbose=1,\n",
        "                     scoring='accuracy')\n",
        "\n",
        "Data_transformed = PowerTransformer().fit_transform(X_test)\n",
        "# veri setindeki dağılımını Gauss dağılımına daha da yaklaştırmak için PowerTransformer ile X_test verisini değiştirdik.\n",
        "\n",
        "gs_NB.fit(Data_transformed, y_test) #değiştirilen veriler ile GridSearch'u eğittik\n",
        "\n",
        "best_parameter_for_gaussian = gs_NB.best_params_\n",
        "print(\"Bulunan En İyi Paramete\", best_parameters)\n",
        "\n",
        "# Gaussian Naive Bayes için Optimal parametreleri kullanarak yeniden modeli eğitiyoruz\n",
        "\n",
        "model = GaussianNB(var_smoothing=best_parameter_for_gaussian['var_smoothing'])\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(f\"Optimizasyon Sonrası Accuracy:  {accuracy_score(y_pred, y_test):.2f}\")\n",
        "print(f\"Optimizasyon Sonrası Precision: {precision_score(y_test, y_pred, average='macro'):.2f}\")\n",
        "print(f\"Optimizasyon Sonrası Recall: {recall_score(y_test, y_pred, average='macro'):.2f}\")\n",
        "print(f\"Optimizasyon Sonrası F1 Score: {f1_score(y_test, y_pred, average='micro'):.2f}\")\n",
        "print(f\"Optimizasyon Sonrası Karışıklık Matrisi:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "7kiVYKHowvwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4aa3ff-3fe0-4562-a320-13e5a73af563"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################### Hiperparamatre Optimizasyonu Öncesi ##########################\n",
            "Accuracy:  0.94\n",
            "Precision: 0.94\n",
            "Recall: 0.94\n",
            "F1 Score: 0.94\n",
            "Karışıklık Matrisi:\n",
            " [[1255  159]\n",
            " [   0 1267]]\n",
            "######################### Hiperparamatre Optimizasyonu Sonrası ##########################\n",
            "Fitting 15 folds for each of 100 candidates, totalling 1500 fits\n",
            "Bulunan En İyi Paramete {'var_smoothing': 0.012328467394420659}\n",
            "Optimizasyon Sonrası Accuracy:  0.99\n",
            "Optimizasyon Sonrası Precision: 0.99\n",
            "Optimizasyon Sonrası Recall: 0.99\n",
            "Optimizasyon Sonrası F1 Score: 0.99\n",
            "Optimizasyon Sonrası Karışıklık Matrisi:\n",
            " [[1396   18]\n",
            " [   0 1267]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Soru 5  Çözümü\n",
        "**1)** Elimizdeki veri setini RandomForestClassifier ile eğittikten sonra aldığım sonuçlar bu şekildeydi:\n",
        "* Accuracy:  0.93\n",
        "* Precision: 0.94\n",
        "* Recall: 0.93\n",
        "* F1 Score: 0.93\n",
        "\n",
        "Ardından modele Random Search ile hiperparametre optimizasyonu yapınca modelimin başarı oranı arttı ve bu değerleri elde ettim:\n",
        "  * Optimizasyon Sonrası Accuracy:  0.99\n",
        "  * Optimizasyon Sonrası Precision: 0.99\n",
        "  * Optimizasyon Sonrası Recall: 0.99\n",
        "  * Optimizasyon Sonrası F1 Score: 0.99\n",
        "\n",
        "**2)** Sınıflandırma için Support Vector Machine kullandığımda değerlendirme metriklerimin değerleri hepsi \"1 \"şeklinde geldi. Bu overfitting olabileceği anlamına geliyor. Daha sonra Random Search ile hipermarametre optimizasyonu yaptığımda sonuç yine aynı kaldı ve tüm metrikler \"1\" sonucunu verdi.\n",
        "Hiperparametre optimiazsyon işlemi en uzun burada gerçekleşti, işlem yaklaşık 8dk sürdü\n",
        "\n",
        "**3)**Gaussian Naive Bayes sınıfandırma kullandığımda ilk öncelikle bu sonuçları aldım:\n",
        "  * Accuracy:  0.94\n",
        "  * Precision: 0.94\n",
        "  * Recall: 0.94\n",
        "  * F1 Score: 0.94\n",
        "  \n",
        "Ardından Grid Search kullanarak hiperparametre optimizasyonu yaptığımda model daha iyi sonuç verdi ve metriklerin değerleri arttı:\n",
        "  * Optimizasyon Sonrası Accuracy:  0.99\n",
        "  * Optimizasyon Sonrası Precision: 0.99\n",
        "  * Optimizasyon Sonrası Recall: 0.99\n",
        "  * Optimizasyon Sonrası F1 Score: 0.99\n"
      ],
      "metadata": {
        "id": "uxTBxK4x8JtW"
      }
    }
  ]
}